{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392936cc-3445-4ecf-8838-c0ebf7e73304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b130ebd-c269-47f7-9d0c-999297ac9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folders\n",
    "# video_size_2019-01-26T11_2019-01-27T11\n",
    "dataset = 'video_sent_2019-01-26T11_2019-01-27T11'\n",
    "buffer_dataset = 'client_buffer_2019-01-26T11_2019-01-27T11'\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "base_path = '' + current_dir + '/puffer_tests/'\n",
    "\n",
    "# Load video_sent data\n",
    "file_path = os.path.join(base_path + dataset + '.csv')    \n",
    "try:\n",
    "    data = pd.read_csv(file_path, dtype=str)\n",
    "    print(f\"Loaded {file_path} with shape {data.shape}\")\n",
    "    data['source_dataset'] = dataset\n",
    "except Exception as e:\n",
    "    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Load client_buffer data\n",
    "file_path = os.path.join(base_path + buffer_dataset + '.csv')\n",
    "try:\n",
    "    buffer_data = pd.read_csv(file_path, dtype=str)\n",
    "    print(f\"Loaded {file_path} with shape {buffer_data.shape}\")\n",
    "    buffer_data['source_dataset'] = buffer_dataset\n",
    "except Exception as e:\n",
    "    print(f\"Error reading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76210207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the time column is numeric\n",
    "data['time (ns GMT)'] = pd.to_numeric(data['time (ns GMT)'], errors='coerce')\n",
    "buffer_data['time (ns GMT)'] = pd.to_numeric(buffer_data['time (ns GMT)'], errors='coerce')\n",
    "\n",
    "# Drop rows with null time values (from coercion or original data)\n",
    "data = data.dropna(subset=['time (ns GMT)', 'session_id'])\n",
    "buffer_data = buffer_data.dropna(subset=['time (ns GMT)', 'session_id'])\n",
    "\n",
    "# Sort both dataframes properly\n",
    "data_sorted = data.sort_values(['time (ns GMT)', 'session_id']).reset_index(drop=True)\n",
    "buffer_sorted = buffer_data.sort_values(['time (ns GMT)', 'session_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge asof (requires full sort on the merge key)\n",
    "merged = pd.merge_asof(\n",
    "    data_sorted,\n",
    "    buffer_sorted,\n",
    "    on='time (ns GMT)',\n",
    "    by='session_id',\n",
    "    direction='backward',\n",
    "    tolerance=10**9 * 10  # 10 seconds\n",
    ")\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06e3dc-1311-4844-a330-e157e09b8a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expt_settings = []\n",
    "with open('expt_settings', 'r') as f:\n",
    "    for line in f:\n",
    "        # Skip line number if present\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # Split off the line number if present (e.g., \"1 {json}\")\n",
    "        parts = line.split(' ', 1)\n",
    "        if len(parts) == 2:\n",
    "            _, json_str = parts\n",
    "        else:\n",
    "            json_str = parts[0]\n",
    "        obj = json.loads(json_str)\n",
    "        expt_settings.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d969d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584d165-3568-4887-8a86-52c227e06abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dfs(data):\n",
    "    # Split the dataframe based on unique values in the 'category' column\n",
    "    return {group: group_df for group, group_df in data.groupby('expt_id')}\n",
    "\n",
    "def split_dfs_merged(data):\n",
    "    # Split the dataframe based on unique values in the 'category' column\n",
    "    return {group: group_df for group, group_df in data.groupby('expt_id_x')}\n",
    "\n",
    "split_dataframes = split_dfs_merged(data)\n",
    "\n",
    "# Create base output directory\n",
    "base_dir = \"ABR_Separated\"\n",
    "\n",
    "# Make sure the base directory exists\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Dictionary to keep count of files saved per ABR\n",
    "abr_counts = {}\n",
    "# Now split_dfs is a dictionary where the key is the category, and the value is the corresponding DataFrame\n",
    "for key, sub_df in split_dataframes.items():\n",
    "    abr_name = expt_settings[int(key)-1][\"abr\"]\n",
    "    abr_dir = os.path.join(base_dir, abr_name)\n",
    "\n",
    "    # Make sure the ABR-specific directory exists\n",
    "    os.makedirs(abr_dir, exist_ok=True)\n",
    "\n",
    "    # Determine filename\n",
    "    count = abr_counts.get(abr_name, 0) + 1\n",
    "    abr_counts[abr_name] = count\n",
    "    filename = f\"{count}.csv\"\n",
    "\n",
    "    # Full path to save\n",
    "    file_path = os.path.join(abr_dir, filename)\n",
    "    sub_df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"Saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651fa05-0ed5-416f-bf79-e12153c4a805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
