{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392936cc-3445-4ecf-8838-c0ebf7e73304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b130ebd-c269-47f7-9d0c-999297ac9541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /Users/Bryce/CS293N/293N-YT-ABR-Prediction/puffer_tests/video_sent_2019-01-26T11_2019-01-27T11.csv with shape (1235841, 14)\n",
      "Loaded /Users/Bryce/CS293N/293N-YT-ABR-Prediction/puffer_tests/client_buffer_2019-01-26T11_2019-01-27T11.csv with shape (7277113, 8)\n"
     ]
    }
   ],
   "source": [
    "# Dataset folders\n",
    "# video_size_2019-01-26T11_2019-01-27T11\n",
    "dataset = 'video_sent_2019-01-26T11_2019-01-27T11'\n",
    "buffer_dataset = 'client_buffer_2019-01-26T11_2019-01-27T11'\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "base_path = '' + current_dir + '/puffer_tests/'\n",
    "\n",
    "# Load video_sent data\n",
    "file_path = os.path.join(base_path + dataset + '.csv')    \n",
    "try:\n",
    "    data = pd.read_csv(file_path, dtype=str)\n",
    "    print(f\"Loaded {file_path} with shape {data.shape}\")\n",
    "    data['source_dataset'] = dataset\n",
    "except Exception as e:\n",
    "    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Load client_buffer data\n",
    "file_path = os.path.join(base_path + buffer_dataset + '.csv')\n",
    "try:\n",
    "    buffer_data = pd.read_csv(file_path, dtype=str)\n",
    "    print(f\"Loaded {file_path} with shape {buffer_data.shape}\")\n",
    "    buffer_data['source_dataset'] = buffer_dataset\n",
    "except Exception as e:\n",
    "    print(f\"Error reading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76210207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the time column is numeric\n",
    "data['time (ns GMT)'] = pd.to_numeric(data['time (ns GMT)'], errors='coerce')\n",
    "buffer_data['time (ns GMT)'] = pd.to_numeric(buffer_data['time (ns GMT)'], errors='coerce')\n",
    "\n",
    "# Drop rows with null time values (from coercion or original data)\n",
    "data = data.dropna(subset=['time (ns GMT)', 'session_id'])\n",
    "buffer_data = buffer_data.dropna(subset=['time (ns GMT)', 'session_id'])\n",
    "\n",
    "# Sort both dataframes properly\n",
    "data_sorted = data.sort_values(['time (ns GMT)', 'session_id']).reset_index(drop=True)\n",
    "buffer_sorted = buffer_data.sort_values(['time (ns GMT)', 'session_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ae6c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               time (ns GMT)                                    session_id  \\\n",
      "0        1548500400111000000  aWhUcIUav1X7UUjGHfMmBaGc7csK55eo+BctXUKCVFs=   \n",
      "1        1548500400329000000  0FWBnkR6ClBRXGEZYDpHQ54JMC9j7UDiwm3Fl3HIPZw=   \n",
      "2        1548500400332000000  c2Gkk+8HfE6AmtgjGRP+tJC4wPZq5U+KAXdJhcBBzKs=   \n",
      "3        1548500400373000000  fciPebAXJYTgwuEwS8Pd9wRVEfd0w3ql1/Nwzhjg2Vs=   \n",
      "4        1548500400444000000  cU1PVL6KeAMIvWujiTuJUjhvIsqhjYr24yUoNip0wl8=   \n",
      "...                      ...                                           ...   \n",
      "1235836  1548586799022000000  u6oPTyb9copR7Buqvetl8/KNXHUX+PSPQrixfmIdqhk=   \n",
      "1235837  1548586799141000000  aWhUcIUav1X7UUjGHfMmBaGc7csK55eo+BctXUKCVFs=   \n",
      "1235838  1548586799577000000  6kZS7bk9TpUTijH2AYl9W/UcFU+idsMXOnhuBfQAnBI=   \n",
      "1235839  1548586799951000000  z0SP/ffaqUbDaMyxVAtPjlR7BksXU47V0XnbMPEg9IU=   \n",
      "1235840  1548586799988000000  7+pBywI9ZapvhuLBGCl67y/fMKmxAHS5X/jwrEmgzrQ=   \n",
      "\n",
      "        index_x expt_id_x channel_x     video_ts        format     size  \\\n",
      "0             0       233       pbs  38277979740  1920x1080-22   693052   \n",
      "1             0       230       cbs  38277799560  1920x1080-22  1095641   \n",
      "2             0       232       fox  38278520280   1280x720-20   702879   \n",
      "3             0       234       fox  38277619380   1280x720-20   692788   \n",
      "4             0       230       cbs  38277979740  1920x1080-22  1057940   \n",
      "...         ...       ...       ...          ...           ...      ...   \n",
      "1235836      14       288       pbs  46052026020  1920x1080-24   279226   \n",
      "1235837      25       280       pbs  46053827820  1920x1080-22   507012   \n",
      "1235838      15       280       pbs  46054008000  1920x1080-22   452320   \n",
      "1235839       0       280       cbs  46053827820  1920x1080-22  1132604   \n",
      "1235840      57       281       nbc  46054368360  1920x1080-22   597159   \n",
      "\n",
      "        ssim_index cwnd  ...    rtt delivery_rate  \\\n",
      "0         0.992577  552  ...  98194       2998515   \n",
      "1          0.98492  172  ...  27245       8206634   \n",
      "2         0.984236  146  ...  49929        905520   \n",
      "3         0.983757   61  ...  47318       1771511   \n",
      "4         0.984239  111  ...  20826       2639927   \n",
      "...            ...  ...  ...    ...           ...   \n",
      "1235836   0.989853   55  ...  80801        881149   \n",
      "1235837   0.989658   52  ...  77162        660683   \n",
      "1235838   0.988937  134  ...  63444       2519280   \n",
      "1235839   0.982718  112  ...  25961        485661   \n",
      "1235840   0.987602  616  ...  31672       2154579   \n",
      "\n",
      "                               source_dataset_x index_y expt_id_y channel_y  \\\n",
      "0        video_sent_2019-01-26T11_2019-01-27T11       0       233       pbs   \n",
      "1        video_sent_2019-01-26T11_2019-01-27T11       0       230       cbs   \n",
      "2        video_sent_2019-01-26T11_2019-01-27T11       0       232       fox   \n",
      "3        video_sent_2019-01-26T11_2019-01-27T11       0       234       fox   \n",
      "4        video_sent_2019-01-26T11_2019-01-27T11       0       230       cbs   \n",
      "...                                         ...     ...       ...       ...   \n",
      "1235836  video_sent_2019-01-26T11_2019-01-27T11      14       288       pbs   \n",
      "1235837  video_sent_2019-01-26T11_2019-01-27T11      25       280       pbs   \n",
      "1235838  video_sent_2019-01-26T11_2019-01-27T11      15       280       pbs   \n",
      "1235839  video_sent_2019-01-26T11_2019-01-27T11       0       280       cbs   \n",
      "1235840  video_sent_2019-01-26T11_2019-01-27T11      57       281       nbc   \n",
      "\n",
      "         event  buffer cum_rebuf                           source_dataset_y  \n",
      "0        timer   14.84     0.187  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "1        timer  14.679      0.23  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "2        timer  14.795     0.564  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "3        timer  14.135     0.682  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "4        timer  14.841     0.146  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "...        ...     ...       ...                                        ...  \n",
      "1235836  timer  14.354     1.334  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "1235837  timer  14.773     0.029  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "1235838  timer  14.779     0.111  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "1235839  timer  14.886     0.101  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "1235840  timer  14.835     0.793  client_buffer_2019-01-26T11_2019-01-27T11  \n",
      "\n",
      "[1235841 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge asof (requires full sort on the merge key)\n",
    "merged = pd.merge_asof(\n",
    "    data_sorted,\n",
    "    buffer_sorted,\n",
    "    on='time (ns GMT)',\n",
    "    by='session_id',\n",
    "    direction='backward',\n",
    "    tolerance=10**9 * 10  # 10 seconds\n",
    ")\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad06e3dc-1311-4844-a330-e157e09b8a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expt_settings = []\n",
    "with open('expt_settings', 'r') as f:\n",
    "    for line in f:\n",
    "        # Skip line number if present\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # Split off the line number if present (e.g., \"1 {json}\")\n",
    "        parts = line.split(' ', 1)\n",
    "        if len(parts) == 2:\n",
    "            _, json_str = parts\n",
    "        else:\n",
    "            json_str = parts[0]\n",
    "        obj = json.loads(json_str)\n",
    "        expt_settings.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d969d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time (ns GMT)', 'session_id', 'index_x', 'expt_id_x', 'channel_x',\n",
      "       'video_ts', 'format', 'size', 'ssim_index', 'cwnd', 'in_flight',\n",
      "       'min_rtt', 'rtt', 'delivery_rate', 'source_dataset_x', 'index_y',\n",
      "       'expt_id_y', 'channel_y', 'event', 'buffer', 'cum_rebuf',\n",
      "       'source_dataset_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = merged\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2584d165-3568-4887-8a86-52c227e06abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ABR_Separated/puffer_ttp/1.csv\n",
      "Saved: ABR_Separated/puffer_ttp/2.csv\n",
      "Saved: ABR_Separated/linear_bba/1.csv\n",
      "Saved: ABR_Separated/linear_bba/2.csv\n",
      "Saved: ABR_Separated/mpc/1.csv\n",
      "Saved: ABR_Separated/mpc/2.csv\n",
      "Saved: ABR_Separated/robust_mpc/1.csv\n",
      "Saved: ABR_Separated/robust_mpc/2.csv\n",
      "Saved: ABR_Separated/pensieve/1.csv\n",
      "Saved: ABR_Separated/pensieve/2.csv\n",
      "Saved: ABR_Separated/puffer_ttp/3.csv\n",
      "Saved: ABR_Separated/puffer_ttp/4.csv\n",
      "Saved: ABR_Separated/puffer_ttp/5.csv\n",
      "Saved: ABR_Separated/puffer_ttp/6.csv\n",
      "Saved: ABR_Separated/puffer_ttp/7.csv\n",
      "Saved: ABR_Separated/linear_bba/3.csv\n",
      "Saved: ABR_Separated/linear_bba/4.csv\n",
      "Saved: ABR_Separated/mpc/3.csv\n",
      "Saved: ABR_Separated/mpc/4.csv\n",
      "Saved: ABR_Separated/robust_mpc/3.csv\n",
      "Saved: ABR_Separated/robust_mpc/4.csv\n",
      "Saved: ABR_Separated/pensieve/3.csv\n",
      "Saved: ABR_Separated/pensieve/4.csv\n",
      "Saved: ABR_Separated/puffer_ttp/8.csv\n",
      "Saved: ABR_Separated/puffer_ttp/9.csv\n",
      "Saved: ABR_Separated/puffer_ttp/10.csv\n",
      "Saved: ABR_Separated/puffer_ttp/11.csv\n",
      "Saved: ABR_Separated/linear_bba/5.csv\n",
      "Saved: ABR_Separated/linear_bba/6.csv\n",
      "Saved: ABR_Separated/mpc/5.csv\n",
      "Saved: ABR_Separated/mpc/6.csv\n",
      "Saved: ABR_Separated/robust_mpc/5.csv\n",
      "Saved: ABR_Separated/robust_mpc/6.csv\n",
      "Saved: ABR_Separated/pensieve/5.csv\n",
      "Saved: ABR_Separated/linear_bba/7.csv\n",
      "Saved: ABR_Separated/mpc/7.csv\n",
      "Saved: ABR_Separated/pensieve/6.csv\n",
      "Saved: ABR_Separated/puffer_ttp/12.csv\n",
      "Saved: ABR_Separated/puffer_ttp/13.csv\n",
      "Saved: ABR_Separated/puffer_ttp/14.csv\n",
      "Saved: ABR_Separated/puffer_ttp/15.csv\n",
      "Saved: ABR_Separated/linear_bba/8.csv\n",
      "Saved: ABR_Separated/linear_bba/9.csv\n",
      "Saved: ABR_Separated/mpc/8.csv\n",
      "Saved: ABR_Separated/mpc/9.csv\n",
      "Saved: ABR_Separated/robust_mpc/7.csv\n",
      "Saved: ABR_Separated/robust_mpc/8.csv\n",
      "Saved: ABR_Separated/pensieve/7.csv\n",
      "Saved: ABR_Separated/pensieve/8.csv\n",
      "Saved: ABR_Separated/puffer_ttp/16.csv\n",
      "Saved: ABR_Separated/puffer_ttp/17.csv\n",
      "Saved: ABR_Separated/puffer_ttp/18.csv\n",
      "Saved: ABR_Separated/puffer_ttp/19.csv\n",
      "Saved: ABR_Separated/linear_bba/10.csv\n",
      "Saved: ABR_Separated/linear_bba/11.csv\n",
      "Saved: ABR_Separated/mpc/10.csv\n",
      "Saved: ABR_Separated/mpc/11.csv\n",
      "Saved: ABR_Separated/robust_mpc/9.csv\n",
      "Saved: ABR_Separated/robust_mpc/10.csv\n",
      "Saved: ABR_Separated/pensieve/9.csv\n",
      "Saved: ABR_Separated/pensieve/10.csv\n"
     ]
    }
   ],
   "source": [
    "def split_dfs(data):\n",
    "    # Split the dataframe based on unique values in the 'category' column\n",
    "    return {group: group_df for group, group_df in data.groupby('expt_id')}\n",
    "\n",
    "def split_dfs_merged(data):\n",
    "    # Split the dataframe based on unique values in the 'category' column\n",
    "    return {group: group_df for group, group_df in data.groupby('expt_id_x')}\n",
    "\n",
    "split_dataframes = split_dfs_merged(data)\n",
    "\n",
    "# Create base output directory\n",
    "base_dir = \"ABR_Separated\"\n",
    "\n",
    "# Make sure the base directory exists\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Dictionary to keep count of files saved per ABR\n",
    "abr_counts = {}\n",
    "# Now split_dfs is a dictionary where the key is the category, and the value is the corresponding DataFrame\n",
    "for key, sub_df in split_dataframes.items():\n",
    "    abr_name = expt_settings[int(key)-1][\"abr\"]\n",
    "    abr_dir = os.path.join(base_dir, abr_name)\n",
    "\n",
    "    # Make sure the ABR-specific directory exists\n",
    "    os.makedirs(abr_dir, exist_ok=True)\n",
    "\n",
    "    # Determine filename\n",
    "    count = abr_counts.get(abr_name, 0) + 1\n",
    "    abr_counts[abr_name] = count\n",
    "    filename = f\"{count}.csv\"\n",
    "\n",
    "    # Full path to save\n",
    "    file_path = os.path.join(abr_dir, filename)\n",
    "    sub_df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"Saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651fa05-0ed5-416f-bf79-e12153c4a805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
